% !TEX root = ../Thesis.tex

\chapter{Konzept und Methodik}
\index{Design!Architektur-Design}%
\index{Planung!Agent-Planung}%
\index{Sicherheit}%
\label{ch:konzept}

\section{Übersicht des Lösungsansatzes}

Aus Kapitel~\ref{ch:hintergrund} abgeleitet entwerfen wir eine referenzierbare Agentenarchitektur für Software Engineering\index{Agentenarchitektur!Entwurf}. Sie kombiniert Planung (ReAct-basierte Policy)\index{Policy-Engine}, Werkzeugnutzung (Linter, Tests, VCS, Dateioperationen)\index{Tool-Integration}, episodisches Gedächtnis und mehrschichtige Sicherheitsmechanismen (Eingabefilter, Sandboxing, Quoten).\footnote{\emph{Referenzierbar} bedeutet hier, dass die Architektur dokumentiert und in anderen Projekten anwendbar ist.}

Der Kern der Architektur folgt dem \emph{Sense-Plan-Act-Reflect}-Zyklus\index{Sense-Plan-Act-Reflect}: Zunächst wird in der \textbf{Sense}-Phase der aktuelle Zustand erfasst, einschließlich Codebase, Fehlermeldungen und Test-Outputs. Darauf aufbauend erfolgt die \textbf{Plan}-Phase mit der Dekomposition des Ziels in ausführbare Teilschritte. In der \textbf{Act}-Phase werden Tool-Aufrufe und Code-Operationen ausgeführt. Abschließend bewertet die \textbf{Reflect}-Phase selbstkritisch die Ergebnisse und passt die Strategie an. Die Schleife wird iterativ wiederholt, bis das Ziel erreicht ist oder eine Abbruchbedingung eintritt (maximale Schritte, Timeout oder Fehlerrate).

\section{Architektur und Design}

Die Architektur basiert auf folgenden Designprinzipien:\footnote{Die Prinzipien orientieren sich an etablierten Softwareentwicklungs-Mustern und Best Practices aus~\cite{sommerville2015software}.}\index{Architekturprinzipien}\index{Best Practices}

\textquote[\cite{richards2020fundamentals}]{Gute Architektur bedeutet, dass Komponenten modular, austauschbar und wartbar sind, um langfristig Wartungskosten zu minimieren.}

\subsection{Designprinzipien}

\begin{sloppypar}
\begin{description}
  \item[Modularität:] Klare Trennung zwischen Policy-Logik, Werkzeugadaptern, Gedächtnis und Sicherheitsschicht. Komponenten kommunizieren über wohldefinierte Schnittstellen.\index{Modularität}
  
  \item[Skalierbarkeit:] Architektur unterstützt parallele Werkzeugausführung\index{Parallelisierung}, asynchrone Operationen\index{Asynchrone Verarbeitung} und Streaming für große Ausgaben.
  
  \item[Wartbarkeit:] Strukturierte Logging\index{Logging}, Tracing und Debugging-Tools. Deterministische Reproduzierbarkeit\index{Reproduzierbarkeit} durch Seed-Control.
  
  \item[Robustheit:] Fehlertoleranz durch Wiederholungslogik, Timeouts, Circuit-Breakers. Graceful Degradation bei Teil-Ausfällen.\index{Retry}\index{Circuit Breaker}\index{Timeout}
  
  \item[Sicherheit:] Defense-in-depth: Eingabevalidierung, Sandboxing, Least-Privilege, Audit-Logging.\index{Sandboxing}\index{Least Privilege}\index{Audit-Logging}
\end{description}
\end{sloppypar}

\subsection{Architekturkomponenten}

Abbildung \ref{fig:agent-architektur} zeigt die Kernkomponenten der Architektur:\footnote{Vgl. \cite{richards2020fundamentals} für detaillierte Architekturprinzipien.}\index{Agentenarchitektur}

\begin{sloppypar}
\begin{description}
  \item[Agent-Controller:] Zentrale Steuerungseinheit. Implementiert die ReAct-Loop (Reasoning, Action, Observation). Nutzt LLM-API für Planung und Reflexion.\index{ReAct}\index{LLM}
  
  \item[Tool-Registry:] Verwaltung verfügbarer Tools mit Metadaten (Name, Beschreibung, Schema, Berechtigungen)\index{Tool-Metadaten}. Ermöglicht Werkzeugerkennung\index{Tool-Discovery} und dynamisches Routing.
  
  \item[Tool-Adapter:] Wrapper für externe Tools (Tests, Linter, VCS)\index{Tool-Wrapper}. Standardisieren Ein-/Ausgabeformate\index{Standardisierung}. Implementieren Wiederholungslogik und Fehlerbehandlung\index{Error-Handling}.
  
  \item[Memory-Manager:] Verwaltet episodisches (konkrete Ereignisse) und semantisches (Wissen) Gedächtnis\index{Episodisches Gedächtnis}. Nutzt Vektor-DB\index{Vektor-Datenbank} für Retrieval-Augmented Generation (RAG)\index{RAG!Memory}.
  
  \item[Sicherheitsschicht:] Interceptor für alle Werkzeugaufrufe. Prüft Berechtigungen, erzwingt Rate-Limits, loggt kritische Operationen. Kann schädliche Aufrufe blockieren.
  
  \item[Kontextmanager:] Optimiert Token-Verbrauch\index{Token-Optimierung} durch intelligentes Pruning, Zusammenfassung\index{Summarization}, Chunking\index{Chunking}. Kritisch für lange Codebases.
\end{description}
\end{sloppypar}

\begin{figure}[ht]
\centering
\resizebox{\textwidth}{!}{%
\begin{tikzpicture}[
  node distance=8mm and 10mm,
  every node/.style={font=\small},
  box/.style={draw, rounded corners, align=center, inner sep=3pt, minimum width=28mm, minimum height=9mm},
  io/.style={draw, align=center, inner sep=3pt, minimum width=24mm, minimum height=7mm},
  >={Stealth[length=2.2mm]}
]
% Nodes
\node[io] (input) {Eingabe\\(Ziel)};
\node[box, right=of input] (controller) {Agent Controller\\(Planung / Policy)};
\node[box, right=of controller] (tools) {Werkzeugadapter\\(Linter, Tests, VCS)};
\node[box, below=of tools] (memory) {Gedächtnis\\(episodisch / semantisch)};
\node[io, right=of tools] (output) {Ausgabe\\(Vorschlag / Patch)};

% Safety layer (fit around core components)
\node[draw, rounded corners, fit=(controller) (tools) (memory), inner sep=6mm, label={[align=center]above:Sicherheitsschicht\\(Sandboxing, Filter, Quoten)}] (safety) {};

% Edges
\draw[->] (input) -- (controller);
\draw[->] (controller) -- (tools);
\draw[->] (tools) -- (output);
\draw[->] (controller) |- (memory);
\draw[->] (memory) -| (controller);

\end{tikzpicture}}
\caption{Agentenarchitektur für Software Engineering mit agentic AI (TikZ-Diagramm)}
\label{fig:agent-architektur}
\end{figure}

\subsection{ReAct-Loop im Detail}

Der Agent Controller implementiert folgende Schleife:

\begin{enumerate}
  \item \textbf{Thought (Reasoning):} LLM generiert Reasoning-Schritt: \enquote{Was weiß ich? Was fehlt? Welcher nächste Schritt ist sinnvoll?}
  
  \item \textbf{Action:} Auswahl und Parametrisierung eines Tools. Beispiel:
  
  \texttt{run\_tests(module="auth")}
  
  \item \textbf{Observation:} Werkzeugausgabe wird strukturiert zurückgegeben. Beispiel: \enquote{3 tests failed in auth/test\_login.py}
  
  \item \textbf{Reflection:} Bewertung des Outputs: \enquote{Erfolgreich? Fehler? Next steps?}
  
  \item Wiederholung oder Terminierung (Ziel erreicht / Max-Steps / Fehler)
\end{enumerate}

Dies entspricht dem in~\cite{yao2023react} beschriebenen Pattern, erweitert um explizite Reflexion~\cite{shinn2023reflexion}.

\subsection{Tool-Interface-Design}

Jedes Tool implementiert ein standardisiertes Schema (siehe Listing~\ref{lst:tool-schema}):

\begin{lstlisting}[style=Python, caption={Tool-Interface-Schema (Pseudocode)}, label={lst:tool-schema}]
class Tool(Protocol):
    name: str                    # eindeutiger Identifier
    description: str             # human-readable Beschreibung
    parameters: JSONSchema       # Input-Parameter als Schema
    required_permissions: List[str]  # z.B. ["fs:read", "process:spawn"]
    
    def execute(self, **kwargs) -> ToolResult:
        """Fuehrt Tool aus und gibt strukturiertes Ergebnis zurueck"""
        pass

@dataclass
class ToolResult:
    success: bool
    output: str | dict
    metadata: dict  # z.B. execution_time, tokens_used
    error: Optional[str]
\end{lstlisting}

Die Standardisierung ermöglicht:
\begin{sloppypar}
\begin{itemize}
  \item Automatische Werkzeugerkennung und -registrierung
  \item Validierung von Inputs durch JSON Schema
  \item Berechtigungsprüfung vor Ausführung
  \item Strukturierte Fehlerbehandlung
\end{itemize}
\end{sloppypar}

\section{Methodik}

Die Entwicklung und Evaluation der Architektur folgt einem systematischen Vorgehen.

\subsection{Entwicklungsmethodik}

Das Vorgehen orientiert sich an Design Science Research \cite{sommerville2015software}:

\begin{enumerate}
  \item \textbf{Anforderungsanalyse:} Ableitung konkreter Requirements aus verwandten Arbeiten und Benchmarks (SWE-bench, HumanEval)
  
  \item \textbf{Architekturdesign:} Entwicklung der Referenzarchitektur (Abbildung~\ref{fig:agent-architektur}) mit Fokus auf Modularität
  
  \item \textbf{Prototyping:} Iterative Implementierung der Kernkomponenten in Python
  
  \item \textbf{Evaluation:} Benchmark-Tests und Metriken-Erhebung (siehe Kapitel~\ref{ch:realisierung})
  
  \item \textbf{Refinement:} Verbesserung basierend auf Evaluationsergebnissen
\end{enumerate}

Abbildung~\ref{fig:agent-workflow} illustriert den ReAct-Zyklus einer agentischen Sitzung. Der Agent empfängt ein Ziel, sammelt Kontext, plant Schritte, führt Tools aus, verarbeitet Feedback und reflektiert über Zwischenergebnisse. Die Schleife wiederholt sich bis das Ziel erreicht oder abgebrochen wird.

\begin{figure}[p!]
\centering
% Ganzseitige Abbildung
\includegraphics[width=\linewidth,height=0.9\textheight,keepaspectratio]{images/agent-workflow.png}
\caption{ReAct Agent Workflow: Zyklisches Reasoning und Acting Paradigma mit Fehlertoleranz}
\label{fig:agent-workflow}
\end{figure}

\subsection{Evaluationsmethodik}

Die Evaluation erfolgt anhand mehrerer Dimensionen:

\begin{sloppypar}
\begin{description}
  \item[Funktionale Korrektheit:] Erfolgsrate bei definierten SE-Tasks (Refactoring, Test-Fixing, Linting)
  
  \item[Effizienz:] Token-Verbrauch, Laufzeit, Anzahl Tool-Calls
  
  \item[Robustheit:] Verhalten bei fehlerhaften Tool-Outputs, malformed Inputs
  
  \item[Sicherheit:] Resistenz gegen Prompt-Injection, unauthorized File-Access
\end{description}
\end{sloppypar}

Konkrete Metriken werden in Kapitel \ref{ch:realisierung} definiert und gemessen.

\subsection{Testszenarien}

Drei repräsentative Szenarien wurden definiert:

\begin{enumerate}
  \item \textbf{Szenario A: Automated Refactoring}
    \begin{sloppypar}
    \begin{itemize}
      \item Ziel: Extract-Function auf komplexe Methode anwenden
      \item Tools: AST-Parser, Linter, Tests
      \item Erfolg: Refactoring korrekt + Tests bestehen
    \end{itemize}
    \end{sloppypar}
  
  \item \textbf{Szenario B: Test Failure Diagnosis}
    \begin{sloppypar}
    \begin{itemize}
      \item Ziel: Failing tests debuggen und fixen
      \item Tools: Test-Runner, Debugger, Code-Editor
      \item Erfolg: Tests grün + keine Regressionen
    \end{itemize}
    \end{sloppypar}
  
  \item \textbf{Szenario C: Code Review Automation}
    \begin{sloppypar}
    \begin{itemize}
      \item Ziel: PR reviewen und Feedback geben
      \item Tools: Diff-Viewer, Static Analysis, Style-Checker
      \item Erfolg: Relevantes Feedback + keine False-Positives
    \end{itemize}
    \end{sloppypar}
\end{enumerate}

Neben der formalen Beschreibung der Szenarien wird im Konzept auch großer Wert auf Reproduzierbarkeit und Praktikabilität gelegt: Für jedes Szenario werden Eingabedaten, erwartete Outputs und Akzeptanzkriterien exakt definiert, so dass Experimente automatisiert wiederholt und Ergebnisse vergleichbar werden. Ferner werden Metriken und Logging-Formate standardisiert, damit unterschiedliche Implementierungen derselben Architektur direkt verglichen werden können. Die Operationalisierung erleichtert nicht nur Validierung, sondern auch Transfer in industrielle Pipelines.

\subsection{Fallbeispiel: Refactoring-Flow}

Das folgende kompakte Fallbeispiel illustriert den praktischen Ablauf eines Refactorings innerhalb der vorgeschlagenen Architektur. Es zeigt, wie Sensieren, Planen, Act und Reflect zusammenwirken, um ein sicheres, getestetes Refactoring durchzuführen.

Beispielablauf (kompakt):
\begin{enumerate}
  \item \textbf{Sense:} AST-basierte Analyse identifiziert eine lange Methode mit hoher Cyclomatic-Complexity; relevante Tests werden bestimmt.
  \item \textbf{Plan:} Agent plant Extract-Function, inklusive Aufrufer-Anpassungen und Test-Aktualisierungen.
  \item \textbf{Act:} Tool-Adapter führt AST-Refactoring aus (Parameter als JSON), erstellt temporären Branch und führt Tests aus.
  \item \textbf{Observation:} Test-Runner liefert strukturierte Ergebnisse, z.\,B.:
  
  \texttt{"failed": ["auth/test\_login.py::test\_login"]}
  \item \textbf{Reflection:} Agent analysiert Fehlermeldungen, generiert einen präzisen Patch-Verfeinerungsvorschlag und wiederholt ggf. die Schleife.
\end{enumerate}

Wichtige Praxispunkte: Diffs werden vor dem Commit automatisch formatiert und durch Linter geprüft; kritische Änderungen durchlaufen ein Human-in-the-Loop-Gate. Logs und Traces werden gespeichert, so dass das Gedächtnis zukünftige Entscheidungen informieren kann.

\section{Sicherheits- und Safety-Mechanismen}

Da Agents Code ausführen und Dateien modifizieren, sind robuste Sicherheitsmechanismen essentiell.

\subsection{Input-Validation}

Alle LLM-generierten Tool-Calls werden validiert:
\begin{itemize}
  \item JSON-Schema-Validierung der Parameter
  \item Whitelisting erlaubter Dateipfade
  \item Bereinigung von Shell-Befehlen
  \item Erkennung von Prompt-Injection-Mustern
\end{itemize}

\subsection{Sandboxing}

Code-Execution erfolgt in isolierten Umgebungen:
\begin{itemize}
  \item Docker-Container mit restriktiven Permissions
  \item Schreibgeschütztes Dateisystem (außer explizit erlaubte Directories)
  \item Netzwerkisolierung (kein Internet-Zugriff außer whitelisted APIs)
  \item Ressourcenlimits (CPU, Memory, Disk)
\end{itemize}

\subsection{Audit-Logging}

Alle kritischen Operationen werden geloggt:
\begin{itemize}
  \item Werkzeugaufrufe mit Zeitstempel, Benutzer, Parametern
  \item Dateimodifikationen (Before/After-Diffs)
  \item Zugriffsverweigerungen und Sicherheitswarnungen
  \item LLM-API-Aufrufe mit Token-Anzahl
\end{itemize}

\subsection{Human-in-the-Loop}

Für kritische Operationen (Deployment, Datenbank-Modifikationen) wird menschliche Bestätigung eingefordert (siehe Listing~\ref{lst:human-approval}):

\begin{lstlisting}[style=Python, caption={Human-Approval-Mechanismus (Pseudocode)}, label={lst:human-approval}]
class HumanApprovalRequired(Exception):
    pass

def execute_critical_tool(tool_name, params):
    if tool_name in CRITICAL_TOOLS:
        print(f"Agent moechte {tool_name} ausfuehren mit {params}")
        approval = input("Approve? [y/N]: ")
        if approval.lower() != 'y':
            raise HumanApprovalRequired()
    
    return execute_tool(tool_name, params)
\end{lstlisting}

\section{Abgrenzung zu alternativen Ansätzen}

Der Ansatz unterscheidet sich von den in Kapitel~\ref{ch:hintergrund} beschriebenen Methoden durch:

\begin{sloppypar}
\begin{itemize}
  \item \textbf{Explizite Sicherheitsmechanismen:} Während viele Forschungsprototypen Safety vernachlässigen, steht es hier im Zentrum
  
  \item \textbf{Referenzarchitektur:} Dokumentierte, wiederverwendbare Architektur statt monolithischem System
  
  \item \textbf{Praxisfokus:} Evaluation anhand realistischer SE-Workflows, nicht nur synthetische Benchmarks
  
  \item \textbf{Werkzeugschnittstellenstandards:} Wiederverwendbare Tool-Adapter statt ad-hoc Integrationen
\end{itemize}
\end{sloppypar}

Die Implementierung und empirische Validierung dieser Konzepte erfolgt in Kapitel~\ref{ch:realisierung}.

Abschließend sei betont, dass das Konzept bewusst pragmatisch gehalten ist: Ziel ist ein praktikabler Kompromiss zwischen Forschungsidealen (maximale Generalität) und den Erfordernissen produktiver Softwareentwicklung (Wartbarkeit, Messbarkeit, Kosten). Deshalb favorisiert das Design wiederverwendbare Schnittstellen und klare Migrationspfade, anstatt ein rein prototypisches System ohne Produktionsreife zu liefern.
